### 1. CUDA中设备内存的分类与特征

| 内存类型  | 物理位置 |   访问权限  | 可见范围 | 生命周期 |
|:------------:|:---------------:|:--------------:|:---------------:|:--------------:|
| 全局内存 | 在芯片外 | 可读可写 | 所有线程和主机端 | 由主机分配与释放 |
| 常量内存 | 在芯片外 | 仅可读 | 所有线程和主机端 | 由主机分配与释放 |
| 纹理和表面内存 | 在芯片外 | 一般仅可读 | 所有线程和主机端 | 由主机分配和释放 |
|寄存器内存|在芯片内|可读可写|单个线程|所在线程| 
|局部内存|在芯片外|可读可写|单个线程|所在线程|
|共享内存|在芯片内|可读可写|单个线程块|所在线程块|

### 2. CUDA中的内存组织示意图

![](./pic/CUDA%E5%86%85%E5%AD%98%E7%BB%84%E7%BB%87%E7%A4%BA%E6%84%8F%E5%9B%BE.png)

### 3. 几个不同能力的GPU中与寄存器和共享内存有关的技术指标

| 计算能力  | 3.5 |   6.0  | 7.0 | 7.5 |
|:------------:|:---------------:|:--------------:|:---------------:|:--------------:|
|GPU代表|Tesla K40|Tesla P100|Tesla V100|GeForce RTX 2080|
|SM寄存器数上限|64K|64K|64K|64K|
|单个线程块寄存器数上限|64K|64K|64K|64K|
|单个线程寄存器数上限|255|255|255|255|
|SM共享内存上限/KB|48|64|96|64|
|单个线程块共享内存上限/KB|48|48|96|64|

### 4. SM及其占有率

#### 4.1 SM的构成

一个GPU是由多个SM(Streaming Multiprocessor)构成的。一个SM包含如下资源：

- (1) 一定数量的**寄存器**。
- (2) 一定数量的**共享内存**。
- (3) 常量内存的缓存。
- (4) 纹理和表面内存的缓存。
- (5) L1缓存。
- (6) 两个（计算能力6.0）或4个（其他计算能力）**线程束调度器**（warp scheduler）用于不同线程的上下文之间迅速地切换，以及为准备就绪的线程束发出执行指令。
- (7) 执行核心，包括：
    - a) 若干整型数运算的核心（INT32）。
    - b) 若干单精度浮点数运算的核心（FP32）。
    - c) 若干双精度浮点数运算的核心（FP64）。
    - d) 若干单精度浮点数超越函数（transcendental functions）的特殊函数单元（special function units, SFUs）。
    - e) 若干混合精度的张量核心（tensor cores，由伏特架构引入，适用于机器学习中的低精度矩阵计算）。

#### 4.2 SM的占有率

要分析SM的理论占用率，需要知道第三节中提到的寄存器和共享内存的上限，还有第2章中提到的**一个线程块（无论几维的）中线程数不能超过1024**限制。还需要知道两个指标：

- (1) 一个SM中最多能拥有的线程块个数为$N_b=16$(开普勒架构和图灵架构)或者$N_b=32$(麦克斯韦架构、帕斯卡架构和伏特架构)。
- (2) 一个SM中最多能拥有的线程个数$N_t=2048$（从开普勒架构到伏特架构）或者$N_t=1024$（图灵架构）。

在并行规模足够大（即核函数执行配置中定义的总线程数足够多）的前提下分几种情况来分析SM的理论占有率：

- (1) **寄存器和共享内存使用量很小的情况**。此时，SM的占有率完全由执行配置中的线程块大小决定。关于线程块大小，读者也许注意到我们之前一直用128。这是因为，SM中线程的执行是以线程束为单位的，所以最好将线程块大小取为线程束大小（32个线程）的整数倍。例如，假设将线程块大小定义为100，那么一个线程块中将有3个完整的线程束（一共96个线程）和一个不完整的线程束（只有4个线程）。在执行核函数中的指令时，不完整的线程束花的时间和完整的线程束花费的时间一样，这就无形中浪费了计算资源。所以，建议将线程块大小取为32的整数倍。在该前提下，任何不小于$N_t/N_b$而且能整除$N_t$的线程块大小都能得到100%的占有率；线程块大小不小于64时其他架构能获得100%的占有率。根据我们列出的数据，线程块大小不小于128时开普勒架构能获得100%的占有率；线程块大小不小于64时其他架构能获得100%的占有率。作者近几年都用一块开普勒架构的Tesla K40开发程序，所以习惯了在一般情况下用128的线程块大小。

- (2) **有限寄存器数量对占有率的约束情况**。我们只针对第三节中列出的几个计算能力进行分析，读者可以类似地分析其他未列出的计算能力。对于第三节中列出的所有计算能力，一个SM最多能使用的寄存器个数为64K（64 x 1024）。除图灵架构外，如果我们希望在一个SM中驻留最多的线程（2048个），核函数中的每个线程最多只能用32个寄存器。当每个线程所用寄存器个数大于64时，SM的占有率将小于50%；当每个线程所用寄存器个数大于128时，SM的占有率将小于25%。对于图灵架构，同样的占有率允许使用更多的寄存器。

- (3) **有限的共享内存对占有率的约束清理**。因为共享内存的数量随着计算能力的上升没有显著的变化规律，所以我们这里仅对计算能力3.5进行分析，对其他计算能力可以类似地分析。如果线程块大小为128，那么每个SM要激活16个线程块才能有2048个线程，达到100%的占有率。此时，一个线程块最多能使用3KB的共享内存。在不改变线程块大小的情况下，要达到50%的占有率，一个线程块最多能使用6KB的共享内存；要达到25%的占有率，一个线程块最多能使用12KB的共享内存。如果一个线程块使用了超过48KB的共享内存，会直接导致核函数无法允许。对其他线程块大小可进行类似的分析。
