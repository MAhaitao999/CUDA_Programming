### 1. CUDA中设备内存的分类与特征

| 内存类型  | 物理位置 |   访问权限  | 可见范围 | 生命周期 |
|:------------:|:---------------:|:--------------:|:---------------:|:--------------:|
| 全局内存 | 在芯片外 | 可读可写 | 所有线程和主机端 | 由主机分配与释放 |
| 常量内存 | 在芯片外 | 仅可读 | 所有线程和主机端 | 由主机分配与释放 |
| 纹理和表面内存 | 在芯片外 | 一般仅可读 | 所有线程和主机端 | 由主机分配和释放 |
|寄存器内存|在芯片内|可读可写|单个线程|所在线程| 
|局部内存|在芯片外|可读可写|单个线程|所在线程|
|共享内存|在芯片内|可读可写|单个线程块|所在线程块|

### 2. CUDA中的内存组织示意图

![](./pic/CUDA%E5%86%85%E5%AD%98%E7%BB%84%E7%BB%87%E7%A4%BA%E6%84%8F%E5%9B%BE.png)

### 3. 几个不同能力的GPU中与寄存器和共享内存有关的技术指标

| 计算能力  | 3.5 |   6.0  | 7.0 | 7.5 |
|:------------:|:---------------:|:--------------:|:---------------:|:--------------:|
|GPU代表|Tesla K40|Tesla P100|Tesla V100|GeForce RTX 2080|
|SM寄存器数上限|64K|64K|64K|64K|
|单个线程块寄存器数上限|64K|64K|64K|64K|
|单个线程寄存器数上限|255|255|255|255|
|SM共享内存上限/KB|48|64|96|64|
|单个线程块共享内存上限/KB|48|48|96|64|

### 4. SM及其占有率

#### 4.1 SM的构成

一个GPU是由多个SM(Streaming Multiprocessor)构成的。一个SM包含如下资源：

- (1) 一定数量的**寄存器**。
- (2) 一定数量的**共享内存**。
- (3) 常量内存的缓存。
- (4) 纹理和表面内存的缓存。
- (5) L1缓存。
- (6) 两个（计算能力6.0）或4个（其他计算能力）**线程束调度器**（warp scheduler）用于不同线程的上下文之间迅速地切换，以及为准备就绪的线程束发出执行指令。
- (7) 执行核心，包括：
    - a) 若干整型数运算的核心（INT32）。
    - b) 若干单精度浮点数运算的核心（FP32）。
    - c) 若干双精度浮点数运算的核心（FP64）。
    - d) 若干单精度浮点数超越函数（transcendental functions）的特殊函数单元（special function units, SFUs）。
    - e) 若干混合精度的张量核心（tensor cores，由伏特架构引入，适用于机器学习中的低精度矩阵计算）。

#### 4.2 SM的占有率

要分析SM的理论占用率，需要知道第三节中提到的寄存器和共享内存的上限，还有第2章中提到的**一个线程块（无论几维的）中线程数不能超过1024**限制。还需要知道两个指标：

- (1) 一个SM中最多能拥有的线程块个数为$N_b=16$(开普勒架构和图灵架构)或者$N_b=32$(麦克斯韦架构、帕斯卡架构和伏特架构)。
- (2) 一个SM中最多能拥有的线程个数$N_t=2048$（从开普勒架构到伏特架构）或者$N_t=1024$（图灵架构）。

在并行规模足够大（即核函数执行配置中定义的总线程数足够多）的前提下分几种情况来分析SM的理论占有率：

- (1) 寄存器和共享内存使用量很小的情况。
